{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ab333c",
   "metadata": {},
   "source": [
    "Ans 1 : **Web Scraping** is an automatic method used to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications¹². Web scraping requires two parts, namely the crawler and the scraper. The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. The scraper, on the other hand, is a specific tool created to extract data from the website.\n",
    "\n",
    "Web Scraping is used because it provides actionable insights to gain a competitive edge over its competitors⁴. It helps in obtaining large amounts of information from a website as quickly as possible, such as large amounts of data from a website to train a Machine Learning algorithm¹. It's also used when you need real-time data from any city worldwide.\n",
    "\n",
    "Here are three areas where Web Scraping is commonly used:\n",
    "1. **Data Analytics & Data Science**: Machine learning algorithms require a large volume of data to improve the accuracy of outputs. Web scraping can help data scientists acquire the required training dataset to train ML models.\n",
    "2. **Marketing & Sales**: For every price elastic product in the market, setting optimal prices is one of the most effective ways to improve revenues. However, competitor pricing needs to be known to determine the most optimal prices.\n",
    "3. **Public Relations**: Data scraping helps companies to collect and gather crucial information about their customer’s reviews, complaints, and praises, through different platforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d346b6b",
   "metadata": {},
   "source": [
    "Ans 2 : Web scraping is the process of extracting data from websites using various methods. Some of the common methods used for web scraping are:\n",
    "\n",
    "•  Manual scraping: This involves manually copying and pasting website data into a spreadsheet or text file. It is the simplest and most time-consuming method of web scraping.\n",
    "\n",
    "•  DOM parsing: This involves using client-side scripts to parse the contents of the web page into a DOM tree, which can be dynamically modified or inspected. This method can handle dynamic and interactive websites that use JavaScript or AJAX.\n",
    "\n",
    "•  HTTP programming: This involves using programming languages or libraries to send HTTP requests to a server and receive HTML or XML responses. This method can handle websites that use cookies, sessions, or authenticationhttps.\n",
    "\n",
    "•  Semantic annotation: This involves using markup languages or standards to annotate the web page with semantic information, such as RDFa, Microdata, or Schema.org. This method can help extract structured data from websites that provide semantic annotations.\n",
    "\n",
    "•  Text grepping: This involves using regular expressions or pattern matching to extract data from the web page text. This method is simple and fast, but it can be prone to errors or inconsistencieshttps.\n",
    "\n",
    "•  Web scraping software: This involves using specialized tools or applications that automate the web scraping process, such as Scrapy, BeautifulSoup, Selenium, or Smartproxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd82f1",
   "metadata": {},
   "source": [
    "Ans 3 : **Beautiful Soup** is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner. Beautiful Soup sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "Beautiful Soup is used because it provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects. It also automatically converts the document to Unicode, so you don’t have to think about encodings. This tool not only helps you scrape but also to clean the data. It's a great tool for extracting information from large unstructured data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45babcdc",
   "metadata": {},
   "source": [
    "Ans 4 : Flask is used in this web scraping project because it is a lightweight and easy-to-use framework that allows us to create a web application that can interact with the web scraper written in Python. Flask provides us with a simple way to render HTML templates, handle user input, and display the scraped data. Flask also supports various extensions that can enhance the functionality of the web application, such as Flask-WTF for form validation, Flask-Mail for sending emails, and Flask-SQLAlchemy for database integration. Flask is a good choice for building web scrapers because it is flexible, modular, and scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343dd0f0",
   "metadata": {},
   "source": [
    "Ans5 : The Aws services which we have used is Aamzone aws serives to deploye the production of our web scrapping project .\n",
    "\n",
    "1. Beanstalk : we have used it to create a server for our project so that we can deployed .\n",
    "2. Codepipeline : we have used it to pused the written code from git to the service so that it is deployed in the server.\n",
    "3. Git: Once we have finised writing the code in our IDE and tested then we have pushed it to the git for deployement . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26101275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
